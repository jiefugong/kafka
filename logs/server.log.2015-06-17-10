[2015-06-17 10:01:27,310] INFO [Offset Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:11:27,310] INFO [Offset Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:17:21,693] INFO [Kafka Server 0], shutting down (kafka.server.KafkaServer)
[2015-06-17 10:17:21,694] INFO [Kafka Server 0], Starting controlled shutdown (kafka.server.KafkaServer)
[2015-06-17 10:17:26,698] WARN [Kafka Server 0], Retrying controlled shutdown after the previous attempt failed... (kafka.server.KafkaServer)
[2015-06-17 10:17:31,712] WARN [Kafka Server 0], Retrying controlled shutdown after the previous attempt failed... (kafka.server.KafkaServer)
[2015-06-17 10:17:36,717] WARN [Kafka Server 0], Retrying controlled shutdown after the previous attempt failed... (kafka.server.KafkaServer)
[2015-06-17 10:17:36,717] WARN [Kafka Server 0], Proceeding to do an unclean shutdown as all the controlled shutdown attempts failed (kafka.server.KafkaServer)
[2015-06-17 10:17:36,722] INFO [Socket Server on Broker 0], Shutting down (kafka.network.SocketServer)
[2015-06-17 10:17:48,614] INFO starting (kafka.server.KafkaServer)
[2015-06-17 10:17:48,618] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2015-06-17 10:17:49,091] FATAL Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
kafka.common.KafkaException: Failed to acquire lock on file .lock in /tmp/kafka-logs. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager$$anonfun$lockLogDirs$1.apply(LogManager.scala:98)
	at kafka.log.LogManager$$anonfun$lockLogDirs$1.apply(LogManager.scala:95)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:95)
	at kafka.log.LogManager.<init>(LogManager.scala:57)
	at kafka.server.KafkaServer.createLogManager(KafkaServer.scala:418)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:129)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:29)
	at kafka.Kafka$.main(Kafka.scala:69)
	at kafka.Kafka.main(Kafka.scala)
[2015-06-17 10:17:49,095] INFO shutting down (kafka.server.KafkaServer)
[2015-06-17 10:17:49,099] INFO shut down completed (kafka.server.KafkaServer)
[2015-06-17 10:17:49,100] FATAL Fatal error during KafkaServerStartable startup. Prepare to shutdown (kafka.server.KafkaServerStartable)
kafka.common.KafkaException: Failed to acquire lock on file .lock in /tmp/kafka-logs. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager$$anonfun$lockLogDirs$1.apply(LogManager.scala:98)
	at kafka.log.LogManager$$anonfun$lockLogDirs$1.apply(LogManager.scala:95)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:95)
	at kafka.log.LogManager.<init>(LogManager.scala:57)
	at kafka.server.KafkaServer.createLogManager(KafkaServer.scala:418)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:129)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:29)
	at kafka.Kafka$.main(Kafka.scala:69)
	at kafka.Kafka.main(Kafka.scala)
[2015-06-17 10:17:49,101] INFO shutting down (kafka.server.KafkaServer)
[2015-06-17 10:18:22,793] INFO starting (kafka.server.KafkaServer)
[2015-06-17 10:18:22,795] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2015-06-17 10:18:23,105] FATAL Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
kafka.common.KafkaException: Failed to acquire lock on file .lock in /tmp/kafka-logs. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager$$anonfun$lockLogDirs$1.apply(LogManager.scala:98)
	at kafka.log.LogManager$$anonfun$lockLogDirs$1.apply(LogManager.scala:95)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:95)
	at kafka.log.LogManager.<init>(LogManager.scala:57)
	at kafka.server.KafkaServer.createLogManager(KafkaServer.scala:418)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:129)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:29)
	at kafka.Kafka$.main(Kafka.scala:69)
	at kafka.Kafka.main(Kafka.scala)
[2015-06-17 10:18:23,108] INFO shutting down (kafka.server.KafkaServer)
[2015-06-17 10:18:23,115] INFO shut down completed (kafka.server.KafkaServer)
[2015-06-17 10:18:23,116] FATAL Fatal error during KafkaServerStartable startup. Prepare to shutdown (kafka.server.KafkaServerStartable)
kafka.common.KafkaException: Failed to acquire lock on file .lock in /tmp/kafka-logs. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager$$anonfun$lockLogDirs$1.apply(LogManager.scala:98)
	at kafka.log.LogManager$$anonfun$lockLogDirs$1.apply(LogManager.scala:95)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:95)
	at kafka.log.LogManager.<init>(LogManager.scala:57)
	at kafka.server.KafkaServer.createLogManager(KafkaServer.scala:418)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:129)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:29)
	at kafka.Kafka$.main(Kafka.scala:69)
	at kafka.Kafka.main(Kafka.scala)
[2015-06-17 10:18:23,118] INFO shutting down (kafka.server.KafkaServer)
[2015-06-17 10:19:14,540] INFO starting (kafka.server.KafkaServer)
[2015-06-17 10:19:14,542] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2015-06-17 10:19:14,844] FATAL Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
kafka.common.KafkaException: Failed to acquire lock on file .lock in /tmp/kafka-logs. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager$$anonfun$lockLogDirs$1.apply(LogManager.scala:98)
	at kafka.log.LogManager$$anonfun$lockLogDirs$1.apply(LogManager.scala:95)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:95)
	at kafka.log.LogManager.<init>(LogManager.scala:57)
	at kafka.server.KafkaServer.createLogManager(KafkaServer.scala:418)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:129)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:29)
	at kafka.Kafka$.main(Kafka.scala:69)
	at kafka.Kafka.main(Kafka.scala)
[2015-06-17 10:19:14,846] INFO shutting down (kafka.server.KafkaServer)
[2015-06-17 10:19:14,850] INFO shut down completed (kafka.server.KafkaServer)
[2015-06-17 10:19:14,851] FATAL Fatal error during KafkaServerStartable startup. Prepare to shutdown (kafka.server.KafkaServerStartable)
kafka.common.KafkaException: Failed to acquire lock on file .lock in /tmp/kafka-logs. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager$$anonfun$lockLogDirs$1.apply(LogManager.scala:98)
	at kafka.log.LogManager$$anonfun$lockLogDirs$1.apply(LogManager.scala:95)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:95)
	at kafka.log.LogManager.<init>(LogManager.scala:57)
	at kafka.server.KafkaServer.createLogManager(KafkaServer.scala:418)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:129)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:29)
	at kafka.Kafka$.main(Kafka.scala:69)
	at kafka.Kafka.main(Kafka.scala)
[2015-06-17 10:19:14,852] INFO shutting down (kafka.server.KafkaServer)
[2015-06-17 10:21:21,105] INFO starting (kafka.server.KafkaServer)
[2015-06-17 10:21:21,107] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2015-06-17 10:21:21,413] FATAL Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
kafka.common.KafkaException: Failed to acquire lock on file .lock in /tmp/kafka-logs. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager$$anonfun$lockLogDirs$1.apply(LogManager.scala:98)
	at kafka.log.LogManager$$anonfun$lockLogDirs$1.apply(LogManager.scala:95)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:95)
	at kafka.log.LogManager.<init>(LogManager.scala:57)
	at kafka.server.KafkaServer.createLogManager(KafkaServer.scala:418)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:129)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:29)
	at kafka.Kafka$.main(Kafka.scala:69)
	at kafka.Kafka.main(Kafka.scala)
[2015-06-17 10:21:21,415] INFO shutting down (kafka.server.KafkaServer)
[2015-06-17 10:21:21,422] INFO shut down completed (kafka.server.KafkaServer)
[2015-06-17 10:21:21,422] FATAL Fatal error during KafkaServerStartable startup. Prepare to shutdown (kafka.server.KafkaServerStartable)
kafka.common.KafkaException: Failed to acquire lock on file .lock in /tmp/kafka-logs. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager$$anonfun$lockLogDirs$1.apply(LogManager.scala:98)
	at kafka.log.LogManager$$anonfun$lockLogDirs$1.apply(LogManager.scala:95)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:95)
	at kafka.log.LogManager.<init>(LogManager.scala:57)
	at kafka.server.KafkaServer.createLogManager(KafkaServer.scala:418)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:129)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:29)
	at kafka.Kafka$.main(Kafka.scala:69)
	at kafka.Kafka.main(Kafka.scala)
[2015-06-17 10:21:21,424] INFO shutting down (kafka.server.KafkaServer)
[2015-06-17 10:21:27,310] INFO [Offset Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:25:36,609] INFO starting (kafka.server.KafkaServer)
[2015-06-17 10:25:36,611] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2015-06-17 10:25:36,906] FATAL Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
kafka.common.KafkaException: Failed to acquire lock on file .lock in /tmp/kafka-logs. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager$$anonfun$lockLogDirs$1.apply(LogManager.scala:98)
	at kafka.log.LogManager$$anonfun$lockLogDirs$1.apply(LogManager.scala:95)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:95)
	at kafka.log.LogManager.<init>(LogManager.scala:57)
	at kafka.server.KafkaServer.createLogManager(KafkaServer.scala:418)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:129)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:29)
	at kafka.Kafka$.main(Kafka.scala:69)
	at kafka.Kafka.main(Kafka.scala)
[2015-06-17 10:25:36,909] INFO shutting down (kafka.server.KafkaServer)
[2015-06-17 10:25:36,914] INFO shut down completed (kafka.server.KafkaServer)
[2015-06-17 10:25:36,915] FATAL Fatal error during KafkaServerStartable startup. Prepare to shutdown (kafka.server.KafkaServerStartable)
kafka.common.KafkaException: Failed to acquire lock on file .lock in /tmp/kafka-logs. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager$$anonfun$lockLogDirs$1.apply(LogManager.scala:98)
	at kafka.log.LogManager$$anonfun$lockLogDirs$1.apply(LogManager.scala:95)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:95)
	at kafka.log.LogManager.<init>(LogManager.scala:57)
	at kafka.server.KafkaServer.createLogManager(KafkaServer.scala:418)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:129)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:29)
	at kafka.Kafka$.main(Kafka.scala:69)
	at kafka.Kafka.main(Kafka.scala)
[2015-06-17 10:25:36,916] INFO shutting down (kafka.server.KafkaServer)
[2015-06-17 10:30:26,447] INFO starting (kafka.server.KafkaServer)
[2015-06-17 10:30:26,451] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2015-06-17 10:30:26,637] INFO Log directory '/tmp/kafka-logs' not found, creating it. (kafka.log.LogManager)
[2015-06-17 10:30:26,647] INFO Loading logs. (kafka.log.LogManager)
[2015-06-17 10:30:26,655] INFO Logs loading complete. (kafka.log.LogManager)
[2015-06-17 10:30:26,656] INFO Starting log cleanup with a period of 30000 ms. (kafka.log.LogManager)
[2015-06-17 10:30:26,660] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2015-06-17 10:30:26,663] WARN No meta.properties file under dir /tmp/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2015-06-17 10:30:26,720] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2015-06-17 10:30:26,722] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
[2015-06-17 10:30:26,752] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-06-17 10:30:26,752] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-06-17 10:30:26,773] INFO [Offset Manager on Broker 0]: Removed 0 expired offsets in 10 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:30:26,836] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2015-06-17 10:30:26,904] INFO [ConsumerCoordinator 0]: Starting up. (kafka.coordinator.ConsumerCoordinator)
[2015-06-17 10:30:26,905] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-06-17 10:30:26,906] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2015-06-17 10:30:26,909] INFO [ConsumerCoordinator 0]: Startup complete. (kafka.coordinator.ConsumerCoordinator)
[2015-06-17 10:30:26,929] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2015-06-17 10:30:26,950] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT -> EndPoint(01641a-jigong.corp.zynga.com,9092,PLAINTEXT) (kafka.utils.ZkUtils$)
[2015-06-17 10:30:26,964] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[2015-06-17 10:30:26,997] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2015-06-17 10:31:53,878] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[2015-06-17 10:31:53,880] INFO Topic creation {"version":1,"partitions":{"0":[0]}} (kafka.admin.AdminUtils$)
[2015-06-17 10:31:53,910] INFO [KafkaApi-0] Auto creation of topic test with 1 partitions and replication factor 1 is successful! (kafka.server.KafkaApis)
[2015-06-17 10:31:53,938] INFO Topic creation {"version":1,"partitions":{"45":[0],"34":[0],"12":[0],"8":[0],"19":[0],"23":[0],"4":[0],"40":[0],"15":[0],"11":[0],"9":[0],"44":[0],"33":[0],"22":[0],"26":[0],"37":[0],"13":[0],"46":[0],"24":[0],"35":[0],"16":[0],"5":[0],"10":[0],"48":[0],"21":[0],"43":[0],"32":[0],"49":[0],"6":[0],"36":[0],"1":[0],"39":[0],"17":[0],"25":[0],"14":[0],"47":[0],"31":[0],"42":[0],"0":[0],"20":[0],"27":[0],"2":[0],"38":[0],"18":[0],"30":[0],"7":[0],"29":[0],"41":[0],"3":[0],"28":[0]}} (kafka.admin.AdminUtils$)
[2015-06-17 10:31:53,941] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful! (kafka.server.KafkaApis)
[2015-06-17 10:31:53,994] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [test,0] (kafka.server.ReplicaFetcherManager)
[2015-06-17 10:31:54,094] INFO Completed load of log test-0 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:54,097] INFO Created log for partition [test,0] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 1073741824, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> delete, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> producer, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:54,098] INFO Partition [test,0] on broker 0: No checkpointed highwatermark is found for partition [test,0] (kafka.cluster.Partition)
[2015-06-17 10:31:55,226] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [__consumer_offsets,32],[__consumer_offsets,16],[__consumer_offsets,49],[__consumer_offsets,44],[__consumer_offsets,28],[__consumer_offsets,17],[__consumer_offsets,23],[__consumer_offsets,7],[__consumer_offsets,4],[__consumer_offsets,29],[__consumer_offsets,35],[__consumer_offsets,3],[__consumer_offsets,24],[__consumer_offsets,41],[__consumer_offsets,0],[__consumer_offsets,38],[__consumer_offsets,13],[__consumer_offsets,8],[__consumer_offsets,5],[__consumer_offsets,39],[__consumer_offsets,36],[__consumer_offsets,40],[__consumer_offsets,45],[__consumer_offsets,15],[__consumer_offsets,33],[__consumer_offsets,37],[__consumer_offsets,21],[__consumer_offsets,6],[__consumer_offsets,11],[__consumer_offsets,20],[__consumer_offsets,47],[__consumer_offsets,2],[__consumer_offsets,27],[__consumer_offsets,34],[__consumer_offsets,9],[__consumer_offsets,22],[__consumer_offsets,42],[__consumer_offsets,14],[__consumer_offsets,25],[__consumer_offsets,10],[__consumer_offsets,48],[__consumer_offsets,31],[__consumer_offsets,18],[__consumer_offsets,19],[__consumer_offsets,12],[__consumer_offsets,46],[__consumer_offsets,43],[__consumer_offsets,1],[__consumer_offsets,26],[__consumer_offsets,30] (kafka.server.ReplicaFetcherManager)
[2015-06-17 10:31:55,238] INFO Completed load of log __consumer_offsets-0 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,239] INFO Created log for partition [__consumer_offsets,0] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,240] INFO Partition [__consumer_offsets,0] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,0] (kafka.cluster.Partition)
[2015-06-17 10:31:55,244] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,0] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,247] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,0] in 2 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,248] INFO Completed load of log __consumer_offsets-29 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,249] INFO Created log for partition [__consumer_offsets,29] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,249] INFO Partition [__consumer_offsets,29] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,29] (kafka.cluster.Partition)
[2015-06-17 10:31:55,250] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,29] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,252] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,29] in 2 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,254] INFO Completed load of log __consumer_offsets-48 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,255] INFO Created log for partition [__consumer_offsets,48] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,256] INFO Partition [__consumer_offsets,48] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,48] (kafka.cluster.Partition)
[2015-06-17 10:31:55,256] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,48] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,259] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,48] in 3 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,260] INFO Completed load of log __consumer_offsets-10 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,262] INFO Created log for partition [__consumer_offsets,10] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,262] INFO Partition [__consumer_offsets,10] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,10] (kafka.cluster.Partition)
[2015-06-17 10:31:55,262] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,10] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,265] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,10] in 2 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,267] INFO Completed load of log __consumer_offsets-45 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,269] INFO Created log for partition [__consumer_offsets,45] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,269] INFO Partition [__consumer_offsets,45] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,45] (kafka.cluster.Partition)
[2015-06-17 10:31:55,269] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,45] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,272] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,45] in 2 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,273] INFO Completed load of log __consumer_offsets-26 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,275] INFO Created log for partition [__consumer_offsets,26] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,275] INFO Partition [__consumer_offsets,26] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,26] (kafka.cluster.Partition)
[2015-06-17 10:31:55,275] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,26] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,276] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,26] in 0 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,279] INFO Completed load of log __consumer_offsets-7 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,280] INFO Created log for partition [__consumer_offsets,7] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,281] INFO Partition [__consumer_offsets,7] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,7] (kafka.cluster.Partition)
[2015-06-17 10:31:55,281] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,7] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,282] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,7] in 1 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,284] INFO Completed load of log __consumer_offsets-42 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,286] INFO Created log for partition [__consumer_offsets,42] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,286] INFO Partition [__consumer_offsets,42] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,42] (kafka.cluster.Partition)
[2015-06-17 10:31:55,286] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,42] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,288] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,42] in 1 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,289] INFO Completed load of log __consumer_offsets-4 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,291] INFO Created log for partition [__consumer_offsets,4] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,291] INFO Partition [__consumer_offsets,4] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,4] (kafka.cluster.Partition)
[2015-06-17 10:31:55,292] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,4] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,293] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,4] in 1 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,295] INFO Completed load of log __consumer_offsets-23 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,297] INFO Created log for partition [__consumer_offsets,23] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,297] INFO Partition [__consumer_offsets,23] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,23] (kafka.cluster.Partition)
[2015-06-17 10:31:55,297] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,23] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,299] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,23] in 1 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,301] INFO Completed load of log __consumer_offsets-1 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,302] INFO Created log for partition [__consumer_offsets,1] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,302] INFO Partition [__consumer_offsets,1] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,1] (kafka.cluster.Partition)
[2015-06-17 10:31:55,303] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,1] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,304] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,1] in 0 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,305] INFO Completed load of log __consumer_offsets-39 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,307] INFO Created log for partition [__consumer_offsets,39] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,307] INFO Partition [__consumer_offsets,39] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,39] (kafka.cluster.Partition)
[2015-06-17 10:31:55,308] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,39] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,309] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,39] in 1 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,311] INFO Completed load of log __consumer_offsets-20 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,312] INFO Created log for partition [__consumer_offsets,20] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,312] INFO Partition [__consumer_offsets,20] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,20] (kafka.cluster.Partition)
[2015-06-17 10:31:55,313] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,20] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,314] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,20] in 1 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,316] INFO Completed load of log __consumer_offsets-17 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,317] INFO Created log for partition [__consumer_offsets,17] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,318] INFO Partition [__consumer_offsets,17] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,17] (kafka.cluster.Partition)
[2015-06-17 10:31:55,318] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,17] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,321] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,17] in 3 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,322] INFO Completed load of log __consumer_offsets-36 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,323] INFO Created log for partition [__consumer_offsets,36] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,323] INFO Partition [__consumer_offsets,36] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,36] (kafka.cluster.Partition)
[2015-06-17 10:31:55,324] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,36] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,330] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,36] in 6 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,334] INFO Completed load of log __consumer_offsets-14 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,335] INFO Created log for partition [__consumer_offsets,14] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,335] INFO Partition [__consumer_offsets,14] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,14] (kafka.cluster.Partition)
[2015-06-17 10:31:55,336] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,14] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,337] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,14] in 0 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,339] INFO Completed load of log __consumer_offsets-33 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,340] INFO Created log for partition [__consumer_offsets,33] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,340] INFO Partition [__consumer_offsets,33] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,33] (kafka.cluster.Partition)
[2015-06-17 10:31:55,341] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,33] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,342] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,33] in 0 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,344] INFO Completed load of log __consumer_offsets-49 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,345] INFO Created log for partition [__consumer_offsets,49] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,346] INFO Partition [__consumer_offsets,49] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,49] (kafka.cluster.Partition)
[2015-06-17 10:31:55,346] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,49] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,347] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,49] in 1 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,349] INFO Completed load of log __consumer_offsets-11 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,351] INFO Created log for partition [__consumer_offsets,11] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,351] INFO Partition [__consumer_offsets,11] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,11] (kafka.cluster.Partition)
[2015-06-17 10:31:55,351] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,11] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,352] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,11] in 0 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,354] INFO Completed load of log __consumer_offsets-30 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,356] INFO Created log for partition [__consumer_offsets,30] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,356] INFO Partition [__consumer_offsets,30] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,30] (kafka.cluster.Partition)
[2015-06-17 10:31:55,356] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,30] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,357] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,30] in 1 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,359] INFO Completed load of log __consumer_offsets-46 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,361] INFO Created log for partition [__consumer_offsets,46] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,361] INFO Partition [__consumer_offsets,46] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,46] (kafka.cluster.Partition)
[2015-06-17 10:31:55,361] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,46] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,362] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,46] in 1 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,364] INFO Completed load of log __consumer_offsets-27 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,366] INFO Created log for partition [__consumer_offsets,27] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,366] INFO Partition [__consumer_offsets,27] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,27] (kafka.cluster.Partition)
[2015-06-17 10:31:55,366] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,27] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,367] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,27] in 1 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,369] INFO Completed load of log __consumer_offsets-8 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,370] INFO Created log for partition [__consumer_offsets,8] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,371] INFO Partition [__consumer_offsets,8] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,8] (kafka.cluster.Partition)
[2015-06-17 10:31:55,371] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,8] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,372] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,8] in 1 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,374] INFO Completed load of log __consumer_offsets-24 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,375] INFO Created log for partition [__consumer_offsets,24] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,375] INFO Partition [__consumer_offsets,24] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,24] (kafka.cluster.Partition)
[2015-06-17 10:31:55,376] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,24] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,376] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,24] in 0 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,378] INFO Completed load of log __consumer_offsets-43 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,380] INFO Created log for partition [__consumer_offsets,43] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,380] INFO Partition [__consumer_offsets,43] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,43] (kafka.cluster.Partition)
[2015-06-17 10:31:55,380] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,43] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,381] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,43] in 1 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,383] INFO Completed load of log __consumer_offsets-5 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,385] INFO Created log for partition [__consumer_offsets,5] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,385] INFO Partition [__consumer_offsets,5] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,5] (kafka.cluster.Partition)
[2015-06-17 10:31:55,385] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,5] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,386] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,5] in 1 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,388] INFO Completed load of log __consumer_offsets-21 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,389] INFO Created log for partition [__consumer_offsets,21] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,389] INFO Partition [__consumer_offsets,21] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,21] (kafka.cluster.Partition)
[2015-06-17 10:31:55,390] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,21] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,390] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,21] in 0 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,393] INFO Completed load of log __consumer_offsets-40 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,394] INFO Created log for partition [__consumer_offsets,40] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,394] INFO Partition [__consumer_offsets,40] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,40] (kafka.cluster.Partition)
[2015-06-17 10:31:55,394] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,40] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,395] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,40] in 1 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,397] INFO Completed load of log __consumer_offsets-2 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,398] INFO Created log for partition [__consumer_offsets,2] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,399] INFO Partition [__consumer_offsets,2] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,2] (kafka.cluster.Partition)
[2015-06-17 10:31:55,399] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,2] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,400] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,2] in 1 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,402] INFO Completed load of log __consumer_offsets-37 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,403] INFO Created log for partition [__consumer_offsets,37] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,403] INFO Partition [__consumer_offsets,37] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,37] (kafka.cluster.Partition)
[2015-06-17 10:31:55,404] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,37] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,404] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,37] in 0 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,407] INFO Completed load of log __consumer_offsets-18 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,408] INFO Created log for partition [__consumer_offsets,18] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,408] INFO Partition [__consumer_offsets,18] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,18] (kafka.cluster.Partition)
[2015-06-17 10:31:55,408] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,18] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,409] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,18] in 1 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,411] INFO Completed load of log __consumer_offsets-15 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,412] INFO Created log for partition [__consumer_offsets,15] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,413] INFO Partition [__consumer_offsets,15] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,15] (kafka.cluster.Partition)
[2015-06-17 10:31:55,413] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,15] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,414] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,15] in 1 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,416] INFO Completed load of log __consumer_offsets-34 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,417] INFO Created log for partition [__consumer_offsets,34] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,418] INFO Partition [__consumer_offsets,34] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,34] (kafka.cluster.Partition)
[2015-06-17 10:31:55,418] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,34] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,419] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,34] in 1 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,421] INFO Completed load of log __consumer_offsets-12 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,422] INFO Created log for partition [__consumer_offsets,12] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,422] INFO Partition [__consumer_offsets,12] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,12] (kafka.cluster.Partition)
[2015-06-17 10:31:55,423] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,12] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,423] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,12] in 0 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,425] INFO Completed load of log __consumer_offsets-31 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,427] INFO Created log for partition [__consumer_offsets,31] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,427] INFO Partition [__consumer_offsets,31] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,31] (kafka.cluster.Partition)
[2015-06-17 10:31:55,427] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,31] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,428] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,31] in 1 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,430] INFO Completed load of log __consumer_offsets-9 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,431] INFO Created log for partition [__consumer_offsets,9] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,431] INFO Partition [__consumer_offsets,9] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,9] (kafka.cluster.Partition)
[2015-06-17 10:31:55,431] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,9] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,432] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,9] in 1 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,434] INFO Completed load of log __consumer_offsets-47 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,435] INFO Created log for partition [__consumer_offsets,47] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,436] INFO Partition [__consumer_offsets,47] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,47] (kafka.cluster.Partition)
[2015-06-17 10:31:55,436] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,47] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,437] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,47] in 0 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,438] INFO Completed load of log __consumer_offsets-19 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,440] INFO Created log for partition [__consumer_offsets,19] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,440] INFO Partition [__consumer_offsets,19] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,19] (kafka.cluster.Partition)
[2015-06-17 10:31:55,440] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,19] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,441] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,19] in 1 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,443] INFO Completed load of log __consumer_offsets-28 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,444] INFO Created log for partition [__consumer_offsets,28] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,444] INFO Partition [__consumer_offsets,28] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,28] (kafka.cluster.Partition)
[2015-06-17 10:31:55,445] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,28] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,445] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,28] in 0 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,447] INFO Completed load of log __consumer_offsets-38 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,448] INFO Created log for partition [__consumer_offsets,38] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,449] INFO Partition [__consumer_offsets,38] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,38] (kafka.cluster.Partition)
[2015-06-17 10:31:55,449] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,38] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,450] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,38] in 1 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,452] INFO Completed load of log __consumer_offsets-35 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,453] INFO Created log for partition [__consumer_offsets,35] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,453] INFO Partition [__consumer_offsets,35] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,35] (kafka.cluster.Partition)
[2015-06-17 10:31:55,454] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,35] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,454] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,35] in 0 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,456] INFO Completed load of log __consumer_offsets-44 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,457] INFO Created log for partition [__consumer_offsets,44] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,458] INFO Partition [__consumer_offsets,44] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,44] (kafka.cluster.Partition)
[2015-06-17 10:31:55,458] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,44] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,460] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,44] in 1 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,461] INFO Completed load of log __consumer_offsets-6 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,462] INFO Created log for partition [__consumer_offsets,6] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,462] INFO Partition [__consumer_offsets,6] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,6] (kafka.cluster.Partition)
[2015-06-17 10:31:55,462] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,6] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,463] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,6] in 1 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,465] INFO Completed load of log __consumer_offsets-25 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,466] INFO Created log for partition [__consumer_offsets,25] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,466] INFO Partition [__consumer_offsets,25] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,25] (kafka.cluster.Partition)
[2015-06-17 10:31:55,467] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,25] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,468] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,25] in 1 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,469] INFO Completed load of log __consumer_offsets-16 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,471] INFO Created log for partition [__consumer_offsets,16] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,471] INFO Partition [__consumer_offsets,16] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,16] (kafka.cluster.Partition)
[2015-06-17 10:31:55,472] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,16] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,473] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,16] in 1 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,474] INFO Completed load of log __consumer_offsets-22 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,475] INFO Created log for partition [__consumer_offsets,22] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,476] INFO Partition [__consumer_offsets,22] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,22] (kafka.cluster.Partition)
[2015-06-17 10:31:55,476] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,22] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,477] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,22] in 1 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,479] INFO Completed load of log __consumer_offsets-41 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,480] INFO Created log for partition [__consumer_offsets,41] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,480] INFO Partition [__consumer_offsets,41] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,41] (kafka.cluster.Partition)
[2015-06-17 10:31:55,480] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,41] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,481] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,41] in 1 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,483] INFO Completed load of log __consumer_offsets-32 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,484] INFO Created log for partition [__consumer_offsets,32] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,485] INFO Partition [__consumer_offsets,32] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,32] (kafka.cluster.Partition)
[2015-06-17 10:31:55,485] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,32] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,486] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,32] in 1 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,487] INFO Completed load of log __consumer_offsets-3 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,489] INFO Created log for partition [__consumer_offsets,3] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,489] INFO Partition [__consumer_offsets,3] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,3] (kafka.cluster.Partition)
[2015-06-17 10:31:55,489] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,3] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,490] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,3] in 1 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,492] INFO Completed load of log __consumer_offsets-13 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:31:55,493] INFO Created log for partition [__consumer_offsets,13] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 104857600, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> compact, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> uncompressed, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:31:55,493] INFO Partition [__consumer_offsets,13] on broker 0: No checkpointed highwatermark is found for partition [__consumer_offsets,13] (kafka.cluster.Partition)
[2015-06-17 10:31:55,494] INFO [Offset Manager on Broker 0]: Loading offsets from [__consumer_offsets,13] (kafka.server.OffsetManager)
[2015-06-17 10:31:55,495] INFO [Offset Manager on Broker 0]: Finished loading offsets from [__consumer_offsets,13] in 0 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:31:55,597] INFO [ConsumerCoordinator 0]: Preparing to rebalance group newestGroup generation 1 (kafka.coordinator.ConsumerCoordinator)
[2015-06-17 10:31:55,601] INFO [ConsumerCoordinator 0]: Rebalancing group newestGroup generation 1 (kafka.coordinator.ConsumerCoordinator)
[2015-06-17 10:31:55,611] INFO [ConsumerCoordinator 0]: Stabilized group newestGroup generation 1 (kafka.coordinator.ConsumerCoordinator)
[2015-06-17 10:34:04,294] INFO [ConsumerCoordinator 0]: Preparing to rebalance group newestGroup generation 2 (kafka.coordinator.ConsumerCoordinator)
[2015-06-17 10:34:04,295] INFO [ConsumerCoordinator 0]: Group newestGroup generation 2 is dead and removed (kafka.coordinator.ConsumerCoordinator)
[2015-06-17 10:38:11,053] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [singlepartition,0] (kafka.server.ReplicaFetcherManager)
[2015-06-17 10:38:11,055] INFO Completed load of log singlepartition-0 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:38:11,057] INFO Created log for partition [singlepartition,0] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 1073741824, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> delete, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> producer, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:38:11,058] INFO Partition [singlepartition,0] on broker 0: No checkpointed highwatermark is found for partition [singlepartition,0] (kafka.cluster.Partition)
[2015-06-17 10:38:46,376] INFO [ConsumerCoordinator 0]: Preparing to rebalance group newestGroup0 generation 1 (kafka.coordinator.ConsumerCoordinator)
[2015-06-17 10:38:46,377] INFO [ConsumerCoordinator 0]: Rebalancing group newestGroup0 generation 1 (kafka.coordinator.ConsumerCoordinator)
[2015-06-17 10:38:46,377] INFO [ConsumerCoordinator 0]: Stabilized group newestGroup0 generation 1 (kafka.coordinator.ConsumerCoordinator)
[2015-06-17 10:40:26,763] INFO [Offset Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:45:58,795] INFO [ConsumerCoordinator 0]: Preparing to rebalance group newestGroup0 generation 2 (kafka.coordinator.ConsumerCoordinator)
[2015-06-17 10:45:58,796] INFO [ConsumerCoordinator 0]: Group newestGroup0 generation 2 is dead and removed (kafka.coordinator.ConsumerCoordinator)
[2015-06-17 10:49:06,138] INFO [ConsumerCoordinator 0]: Preparing to rebalance group testGroup generation 1 (kafka.coordinator.ConsumerCoordinator)
[2015-06-17 10:49:06,138] INFO [ConsumerCoordinator 0]: Rebalancing group testGroup generation 1 (kafka.coordinator.ConsumerCoordinator)
[2015-06-17 10:49:06,139] INFO [ConsumerCoordinator 0]: Stabilized group testGroup generation 1 (kafka.coordinator.ConsumerCoordinator)
[2015-06-17 10:49:18,240] INFO [ConsumerCoordinator 0]: Preparing to rebalance group testGroup generation 2 (kafka.coordinator.ConsumerCoordinator)
[2015-06-17 10:49:48,242] INFO [ConsumerCoordinator 0]: Rebalancing group testGroup generation 2 (kafka.coordinator.ConsumerCoordinator)
[2015-06-17 10:49:48,243] INFO [ConsumerCoordinator 0]: Stabilized group testGroup generation 2 (kafka.coordinator.ConsumerCoordinator)
[2015-06-17 10:50:18,140] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [multiplepartitions,5],[multiplepartitions,3],[multiplepartitions,1],[multiplepartitions,0],[multiplepartitions,4],[multiplepartitions,2] (kafka.server.ReplicaFetcherManager)
[2015-06-17 10:50:18,144] INFO Completed load of log multiplepartitions-4 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:50:18,145] INFO Created log for partition [multiplepartitions,4] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 1073741824, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> delete, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> producer, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:50:18,147] INFO Partition [multiplepartitions,4] on broker 0: No checkpointed highwatermark is found for partition [multiplepartitions,4] (kafka.cluster.Partition)
[2015-06-17 10:50:18,149] INFO Completed load of log multiplepartitions-1 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:50:18,150] INFO Created log for partition [multiplepartitions,1] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 1073741824, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> delete, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> producer, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:50:18,151] INFO Partition [multiplepartitions,1] on broker 0: No checkpointed highwatermark is found for partition [multiplepartitions,1] (kafka.cluster.Partition)
[2015-06-17 10:50:18,153] INFO Completed load of log multiplepartitions-5 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:50:18,154] INFO Created log for partition [multiplepartitions,5] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 1073741824, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> delete, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> producer, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:50:18,156] INFO Partition [multiplepartitions,5] on broker 0: No checkpointed highwatermark is found for partition [multiplepartitions,5] (kafka.cluster.Partition)
[2015-06-17 10:50:18,158] INFO Completed load of log multiplepartitions-2 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:50:18,159] INFO Created log for partition [multiplepartitions,2] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 1073741824, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> delete, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> producer, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:50:18,161] INFO Partition [multiplepartitions,2] on broker 0: No checkpointed highwatermark is found for partition [multiplepartitions,2] (kafka.cluster.Partition)
[2015-06-17 10:50:18,163] INFO Completed load of log multiplepartitions-3 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:50:18,164] INFO Created log for partition [multiplepartitions,3] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 1073741824, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> delete, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> producer, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:50:18,165] INFO Partition [multiplepartitions,3] on broker 0: No checkpointed highwatermark is found for partition [multiplepartitions,3] (kafka.cluster.Partition)
[2015-06-17 10:50:18,167] INFO Completed load of log multiplepartitions-0 with log end offset 0 (kafka.log.Log)
[2015-06-17 10:50:18,168] INFO Created log for partition [multiplepartitions,0] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 1073741824, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> delete, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, compression.type -> producer, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 86400000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2015-06-17 10:50:18,169] INFO Partition [multiplepartitions,0] on broker 0: No checkpointed highwatermark is found for partition [multiplepartitions,0] (kafka.cluster.Partition)
[2015-06-17 10:50:26,762] INFO [Offset Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds. (kafka.server.OffsetManager)
[2015-06-17 10:50:28,263] INFO [ConsumerCoordinator 0]: Preparing to rebalance group testGroup generation 3 (kafka.coordinator.ConsumerCoordinator)
[2015-06-17 10:50:28,263] INFO [ConsumerCoordinator 0]: Group testGroup generation 3 is dead and removed (kafka.coordinator.ConsumerCoordinator)
[2015-06-17 10:51:01,103] INFO [ConsumerCoordinator 0]: Preparing to rebalance group multipleGroup0 generation 1 (kafka.coordinator.ConsumerCoordinator)
[2015-06-17 10:51:01,103] INFO [ConsumerCoordinator 0]: Rebalancing group multipleGroup0 generation 1 (kafka.coordinator.ConsumerCoordinator)
[2015-06-17 10:51:01,104] INFO [ConsumerCoordinator 0]: Stabilized group multipleGroup0 generation 1 (kafka.coordinator.ConsumerCoordinator)
[2015-06-17 10:51:50,500] INFO [ConsumerCoordinator 0]: Preparing to rebalance group multipleGroup0 generation 2 (kafka.coordinator.ConsumerCoordinator)
[2015-06-17 10:52:20,505] INFO [ConsumerCoordinator 0]: Rebalancing group multipleGroup0 generation 2 (kafka.coordinator.ConsumerCoordinator)
[2015-06-17 10:52:20,506] INFO [ConsumerCoordinator 0]: Stabilized group multipleGroup0 generation 2 (kafka.coordinator.ConsumerCoordinator)
[2015-06-17 10:59:30,581] INFO [ConsumerCoordinator 0]: Preparing to rebalance group multipleGroup0 generation 3 (kafka.coordinator.ConsumerCoordinator)
[2015-06-17 10:59:30,581] INFO [ConsumerCoordinator 0]: Group multipleGroup0 generation 3 is dead and removed (kafka.coordinator.ConsumerCoordinator)
[2015-06-17 10:59:54,707] INFO [ConsumerCoordinator 0]: Preparing to rebalance group testGroup0 generation 1 (kafka.coordinator.ConsumerCoordinator)
[2015-06-17 10:59:54,708] INFO [ConsumerCoordinator 0]: Rebalancing group testGroup0 generation 1 (kafka.coordinator.ConsumerCoordinator)
[2015-06-17 10:59:54,708] INFO [ConsumerCoordinator 0]: Stabilized group testGroup0 generation 1 (kafka.coordinator.ConsumerCoordinator)
